---
title: "第29天：在完全不懂的领域做产品，我学到了什么"
date: "2026-02-18"
summary: "盘盘猫开发日记最终篇：29天，1,134次commit，9个产品线。关于AI增强开发、零知识领域创业、以及产品与工程分界线的思考。"
tags: ["AI", "Software Development"]
series: "盘盘猫开发日记"
part: 7
type: "Post"
status: "Published"
---

29天。1,134次commit。109个PR。9个产品线。而开发者本人到现在查天干是什么还得翻资料。

这篇最终日记不是总结——系列文章已经覆盖了那些内容。这篇写的是最后两天的基础设施工作，让平台真正达到了生产级别，以及我留到最后才解决的最难的技术问题。

## Portal主题Bug（PR #67 — 30个文件）

每个应用都有自己的CSS主题：`.theme-hub`用深蓝色，`.theme-tarot`用神秘紫，`.theme-bazi`用传统红。9个应用，9种不同的视觉风格。

React portals把它们全搞坏了。

`createPortal(content, document.body)`把DOM节点渲染到document根节点，完全在应用的主题包裹div之外。作用在`.theme-hub`上的CSS变量对modal和dropdown的内容来说是不可见的，因为CSS继承走的是DOM树，不是React组件树。

第一次修复（PR #64）很丑陋：每个modal组件用`closest('.theme-hub')`来检测自己在哪个主题里，然后硬编码一个`.theme-hub-overlay`类。这意味着要对9个主题下的13个使用portal的组件逐一打补丁。完全不可扩展。

PR #67是正确的解法：

- **`ThemeProvider`** — React context，由应用布局设置，声明当前活跃的主题类

- **`useThemeClass()`** — hook，从context中读取当前主题

- **`ThemedPortal`** — `createPortal(content, document.body)`的直接替代品，用正确的主题类加上通过MutationObserver监听的暗色模式类来包裹portal内容

9个应用布局更新，13个portal组件迁移，所有逐组件的hack全部移除。干净、可扩展、正确。

这种bug在开发时看不出来（你一次只测试一个应用），但在生产环境中痛苦至极（用户打开一个modal，颜色全是错的）。

## 弹性AI流式传输（PR #105 — 56个文件）

整个项目中最大的基础设施PR。问题：如果用户在流式传输过程中断网（在手机上很常见，在中国尤其常见），他们会丢失整个测算结果，积分也扣了。

解决方案：**服务端流式缓冲。** 所有19个AI流式路由现在都通过`StreamBufferManager`将数据块缓冲到`stream_buffers`数据库表中。架构如下：

```javascript
AI Provider ──stream──▶ Server (ReadableStream)
                           │
                    ┌──────┴──────┐
                    │             │
              SSE to Client    Periodic flush
              (real-time)      to Supabase DB
                    │             │
                    ▼           ▼
              User sees      Buffer saved
              live stream    for recovery
```

如果客户端断开连接，可以通过`GET /api/stream/{id}`恢复完整响应。一个统一的`useAIStream` hook替换了14个组件中3种不一致的SSE消费模式。`/api/cron/cleanup-streams`定时任务每15分钟清理过期的缓冲。

令人意外的结果：尽管添加了整套弹性基础设施，代码净减少了**186行**。统一的hook比它替换的3种模式更简洁。

## 内容过滤器v3（PR #104 — 14个文件）

内容过滤器在项目中经历了三次迭代：

- **V1**：DFA关键词过滤。直接封锁包含敏感词的整条消息。

- **V2**：流感知过滤（PR #78）。但当敏感词出现时会截断整个流——用户积分扣了，只得到残缺的测算结果。用户体验极差。

- **V3（PR #104）**：行内遮罩。敏感词被替换为`**检测到违禁词**`，流式传输不中断继续。

V3的架构是双重过滤：

- **输入过滤**（严格）：在AI处理之前拦截广告、政治、色情、违法内容

- **输出过滤**（宽松）：相同的分类但去掉了"广告"类别，因为算命AI自然会生成像兼职、招聘、桑拿这样的词，会被粗暴的关键词过滤误标为广告

流式过滤器做边界安全遮罩：它先对完整的累积缓冲区做遮罩处理，然后再分割为已释放/待判定部分，确保跨数据块边界的词也能被捕获。

6个测试文件，158个测试。

## i18n集中化（PR #102 — 10个文件）

到这个阶段，标签定义散落在3个消费方：历史记录管理弹窗、积分历史映射、以及历史配置。180行的行内标签映射以略有不同的格式重复出现。

PR #102将所有内容整合到`packages/i18n/src/labels/`下的两个集中文件：`features.ts`（应用名称、简短标签、子类型标签、图标、时间过滤器、历史标题）和`actions.ts`（约60个积分操作标签）。结果：消费方减少223行，集中源增加607行。以后新增标签只需改一处。

## 中国AI法规合规（PR #83 — 9个文件）

将法律页面拆分为中英文两个版本，带语言切换UI和浏览器语言自动检测。新增中国AI法规合规内容：

- 生成式人工智能服务管理暂行办法

- 深度合成管理规定

- 算法推荐管理规定

加上PIPL跨境传输机制、敏感个人信息同意、自动化决策透明度、以及72小时内监管通报的5步数据泄露应急程序。

如果你面向中国用户做AI产品，这些不是可选项，而且一点都不简单。

## 数据总览

## 接下来做什么

这个项目从来不是关于算命的。它是在验证一个假设：一个工程师，借助AI增强，能不能在一个自己完全不懂的领域，从零开始构建一个真正的多产品平台？

答案是：能。领域知识的鸿沟是可以跨越的。开发速度是真实的。而做一个产品——完整的产品，不只是工程部分——是我这几年做过的最有意思的事。

*完整系列：第1篇（为什么做）、第2篇（怎么做）、第3篇（经验教训）涵盖了浓缩版的故事。这些日记是原始的、逐日记录的版本。*
